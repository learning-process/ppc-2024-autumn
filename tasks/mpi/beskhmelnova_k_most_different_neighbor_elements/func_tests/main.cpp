#include <gtest/gtest.h>

<<<<<<< HEAD
#include "mpi/beskhmelnova_k_most_different_neighbor_elements/include/mpi.hpp"
#include "mpi/beskhmelnova_k_most_different_neighbor_elements/src/mpi.cpp"

// TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_int_100) {
//   boost::mpi::communicator world;
//   std::vector<int> global_vec;
//   std::vector<int32_t> global_out(2);
//
//   // Create TaskData
//   std::shared_ptr<ppc::core::TaskData> taskDataPar = std::make_shared<ppc::core::TaskData>();
//
//   if (world.rank() == 0) {
//     const int count_size_vector = 100;
//     global_vec = beskhmelnova_k_most_different_neighbor_elements_mpi::getRandomVector<int>(count_size_vector);
//     taskDataPar->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
//     taskDataPar->inputs_count.emplace_back(global_vec.size());
//     taskDataPar->outputs.emplace_back(reinterpret_cast<uint8_t*>(global_out.data()));
//     taskDataPar->outputs_count.emplace_back(global_out.size());
//   }
//
//   // Create Task
//   beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskParallel<int> testMpiTaskParallel(taskDataPar);
//   ASSERT_EQ(testMpiTaskParallel.validation(), true);
//   testMpiTaskParallel.pre_processing();
//   testMpiTaskParallel.run();
//   testMpiTaskParallel.post_processing();
//
//   if (world.rank() == 0) {
//     // Create data
//     std::vector<int32_t> reference_out(2);
//
//     // Create TaskData
//     std::shared_ptr<ppc::core::TaskData> taskDataSeq = std::make_shared<ppc::core::TaskData>();
//     taskDataSeq->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
//     taskDataSeq->inputs_count.emplace_back(global_vec.size());
//     taskDataSeq->outputs.emplace_back(reinterpret_cast<uint8_t*>(reference_out.data()));
//     taskDataSeq->outputs_count.emplace_back(reference_out.size());
//
//     // Create Task
//     beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskSequential<int>
//     testMpiTaskSequential(taskDataSeq); ASSERT_EQ(testMpiTaskSequential.validation(), true);
//     testMpiTaskSequential.pre_processing();
//     testMpiTaskSequential.run();
//     testMpiTaskSequential.post_processing();
//
//     ASSERT_EQ(reference_out[0], global_out[0]);
//     ASSERT_EQ(reference_out[1], global_out[1]);
//   }
// }

// TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_int_10000) {
//   boost::mpi::communicator world;
//   std::vector<int> global_vec;
//   std::vector<int32_t> global_out(2);
//
//   // Create TaskData
//   std::shared_ptr<ppc::core::TaskData> taskDataPar = std::make_shared<ppc::core::TaskData>();
//
//   if (world.rank() == 0) {
//     const int count_size_vector = 10000;
//     global_vec = beskhmelnova_k_most_different_neighbor_elements_mpi::getRandomVector<int>(count_size_vector);
//     taskDataPar->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
//     taskDataPar->inputs_count.emplace_back(global_vec.size());
//     taskDataPar->outputs.emplace_back(reinterpret_cast<uint8_t*>(global_out.data()));
//     taskDataPar->outputs_count.emplace_back(global_out.size());
//   }
//
//   // Create Task
//   beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskParallel<int> testMpiTaskParallel(taskDataPar);
//   ASSERT_EQ(testMpiTaskParallel.validation(), true);
//   testMpiTaskParallel.pre_processing();
//   testMpiTaskParallel.run();
//   testMpiTaskParallel.post_processing();
//
//   if (world.rank() == 0) {
//     // Create data
//     std::vector<int32_t> reference_out(2);
//
//     // Create TaskData
//     std::shared_ptr<ppc::core::TaskData> taskDataSeq = std::make_shared<ppc::core::TaskData>();
//     taskDataSeq->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
//     taskDataSeq->inputs_count.emplace_back(global_vec.size());
//     taskDataSeq->outputs.emplace_back(reinterpret_cast<uint8_t*>(reference_out.data()));
//     taskDataSeq->outputs_count.emplace_back(reference_out.size());
//
//     // Create Task
//     beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskSequential<int>
//     testMpiTaskSequential(taskDataSeq); ASSERT_EQ(testMpiTaskSequential.validation(), true);
//     testMpiTaskSequential.pre_processing();
//     testMpiTaskSequential.run();
//     testMpiTaskSequential.post_processing();
//
//     ASSERT_EQ(reference_out[0], global_out[0]);
//     ASSERT_EQ(reference_out[1], global_out[1]);
//   }
// }

TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_double_100) {
=======
#include <boost/mpi/communicator.hpp>

#include "mpi/beskhmelnova_k_most_different_neighbor_elements/include/mpi.hpp"
#include "mpi/beskhmelnova_k_most_different_neighbor_elements/src/mpi.cpp"

TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_size_100) {
>>>>>>> upstream/master
  boost::mpi::communicator world;
  std::vector<double> global_vec;
  std::vector<double> global_out(2);

  // Create TaskData
  std::shared_ptr<ppc::core::TaskData> taskDataPar = std::make_shared<ppc::core::TaskData>();

  if (world.rank() == 0) {
    const int count_size_vector = 100;
    global_vec = beskhmelnova_k_most_different_neighbor_elements_mpi::getRandomVector<double>(count_size_vector);
    taskDataPar->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataPar->inputs_count.emplace_back(global_vec.size());
    taskDataPar->outputs.emplace_back(reinterpret_cast<uint8_t*>(global_out.data()));
    taskDataPar->outputs_count.emplace_back(global_out.size());
  }

  // Create Task
  beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskParallel<double> testMpiTaskParallel(taskDataPar);
  ASSERT_EQ(testMpiTaskParallel.validation(), true);
  testMpiTaskParallel.pre_processing();
  testMpiTaskParallel.run();
  testMpiTaskParallel.post_processing();

  if (world.rank() == 0) {
    // Create data
    std::vector<double> reference_out(2);

    // Create TaskData
    std::shared_ptr<ppc::core::TaskData> taskDataSeq = std::make_shared<ppc::core::TaskData>();
    taskDataSeq->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataSeq->inputs_count.emplace_back(global_vec.size());
    taskDataSeq->outputs.emplace_back(reinterpret_cast<uint8_t*>(reference_out.data()));
    taskDataSeq->outputs_count.emplace_back(reference_out.size());

    // Create Task
    beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskSequential<double> testMpiTaskSequential(
        taskDataSeq);
    ASSERT_EQ(testMpiTaskSequential.validation(), true);
    testMpiTaskSequential.pre_processing();
    testMpiTaskSequential.run();
    testMpiTaskSequential.post_processing();

    ASSERT_NEAR(reference_out[0], global_out[0], 1e-10);
    ASSERT_NEAR(reference_out[1], global_out[1], 1e-10);
  }
}

<<<<<<< HEAD
TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_double_10000) {
=======
TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_size_100_with_equal_elements) {
  boost::mpi::communicator world;
  std::vector<double> global_vec(100, 1);
  std::vector<double> global_out(2);

  // Create TaskData
  std::shared_ptr<ppc::core::TaskData> taskDataPar = std::make_shared<ppc::core::TaskData>();

  if (world.rank() == 0) {
    taskDataPar->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataPar->inputs_count.emplace_back(global_vec.size());
    taskDataPar->outputs.emplace_back(reinterpret_cast<uint8_t*>(global_out.data()));
    taskDataPar->outputs_count.emplace_back(global_out.size());
  }

  // Create Task
  beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskParallel<double> testMpiTaskParallel(taskDataPar);
  ASSERT_EQ(testMpiTaskParallel.validation(), true);
  testMpiTaskParallel.pre_processing();
  testMpiTaskParallel.run();
  testMpiTaskParallel.post_processing();

  if (world.rank() == 0) {
    // Create data
    std::vector<double> reference_out(2);

    // Create TaskData
    std::shared_ptr<ppc::core::TaskData> taskDataSeq = std::make_shared<ppc::core::TaskData>();
    taskDataSeq->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataSeq->inputs_count.emplace_back(global_vec.size());
    taskDataSeq->outputs.emplace_back(reinterpret_cast<uint8_t*>(reference_out.data()));
    taskDataSeq->outputs_count.emplace_back(reference_out.size());

    // Create Task
    beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskSequential<double> testMpiTaskSequential(
        taskDataSeq);
    ASSERT_EQ(testMpiTaskSequential.validation(), true);
    testMpiTaskSequential.pre_processing();
    testMpiTaskSequential.run();
    testMpiTaskSequential.post_processing();

    ASSERT_NEAR(reference_out[0], global_out[0], 1e-10);
    ASSERT_NEAR(reference_out[1], global_out[1], 1e-10);
  }
}

TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_size_10000) {
>>>>>>> upstream/master
  boost::mpi::communicator world;
  std::vector<double> global_vec;
  std::vector<double> global_out(2);

  // Create TaskData
  std::shared_ptr<ppc::core::TaskData> taskDataPar = std::make_shared<ppc::core::TaskData>();

  if (world.rank() == 0) {
    const int count_size_vector = 10000;
    global_vec = beskhmelnova_k_most_different_neighbor_elements_mpi::getRandomVector<double>(count_size_vector);
    taskDataPar->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataPar->inputs_count.emplace_back(global_vec.size());
    taskDataPar->outputs.emplace_back(reinterpret_cast<uint8_t*>(global_out.data()));
    taskDataPar->outputs_count.emplace_back(global_out.size());
  }

  // Create Task
  beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskParallel<double> testMpiTaskParallel(taskDataPar);
  ASSERT_EQ(testMpiTaskParallel.validation(), true);
  testMpiTaskParallel.pre_processing();
  testMpiTaskParallel.run();
  testMpiTaskParallel.post_processing();

  if (world.rank() == 0) {
    // Create data
    std::vector<double> reference_out(2);

    // Create TaskData
    std::shared_ptr<ppc::core::TaskData> taskDataSeq = std::make_shared<ppc::core::TaskData>();
    taskDataSeq->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataSeq->inputs_count.emplace_back(global_vec.size());
    taskDataSeq->outputs.emplace_back(reinterpret_cast<uint8_t*>(reference_out.data()));
    taskDataSeq->outputs_count.emplace_back(reference_out.size());

    // Create Task
    beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskSequential<double> testMpiTaskSequential(
        taskDataSeq);
    ASSERT_EQ(testMpiTaskSequential.validation(), true);
    testMpiTaskSequential.pre_processing();
    testMpiTaskSequential.run();
    testMpiTaskSequential.post_processing();

    ASSERT_NEAR(reference_out[0], global_out[0], 1e-10);
    ASSERT_NEAR(reference_out[1], global_out[1], 1e-10);
  }
}

<<<<<<< HEAD
TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_double_uneven_size_10001) {
=======
TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_uneven_size_10001) {
>>>>>>> upstream/master
  boost::mpi::communicator world;
  std::vector<double> global_vec;
  std::vector<double> global_out(2);

  // Create TaskData
  std::shared_ptr<ppc::core::TaskData> taskDataPar = std::make_shared<ppc::core::TaskData>();

  if (world.rank() == 0) {
    const int count_size_vector = 1001;
    global_vec = beskhmelnova_k_most_different_neighbor_elements_mpi::getRandomVector<double>(count_size_vector);
    taskDataPar->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataPar->inputs_count.emplace_back(global_vec.size());
    taskDataPar->outputs.emplace_back(reinterpret_cast<uint8_t*>(global_out.data()));
    taskDataPar->outputs_count.emplace_back(global_out.size());
  }

  // Create Task
  beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskParallel<double> testMpiTaskParallel(taskDataPar);
  ASSERT_EQ(testMpiTaskParallel.validation(), true);
  testMpiTaskParallel.pre_processing();
  testMpiTaskParallel.run();
  testMpiTaskParallel.post_processing();

  if (world.rank() == 0) {
    // Create data
    std::vector<double> reference_out(2);

    // Create TaskData
    std::shared_ptr<ppc::core::TaskData> taskDataSeq = std::make_shared<ppc::core::TaskData>();
    taskDataSeq->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataSeq->inputs_count.emplace_back(global_vec.size());
    taskDataSeq->outputs.emplace_back(reinterpret_cast<uint8_t*>(reference_out.data()));
    taskDataSeq->outputs_count.emplace_back(reference_out.size());

    // Create Task
    beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskSequential<double> testMpiTaskSequential(
        taskDataSeq);
    ASSERT_EQ(testMpiTaskSequential.validation(), true);
    testMpiTaskSequential.pre_processing();
    testMpiTaskSequential.run();
    testMpiTaskSequential.post_processing();

    ASSERT_NEAR(reference_out[0], global_out[0], 1e-10);
    ASSERT_NEAR(reference_out[1], global_out[1], 1e-10);
  }
}

<<<<<<< HEAD
int main(int argc, char** argv) {
  boost::mpi::environment env(argc, argv);
  boost::mpi::communicator world;
  ::testing::InitGoogleTest(&argc, argv);
  ::testing::TestEventListeners& listeners = ::testing::UnitTest::GetInstance()->listeners();
  if (world.rank() != 0) {
    delete listeners.Release(listeners.default_result_printer());
  }
  return RUN_ALL_TESTS();
=======
TEST(beskhmelnova_k_most_different_neighbor_elements_mpi, Test_vector_size_100000) {
  boost::mpi::communicator world;
  std::vector<double> global_vec;
  std::vector<double> global_out(2);

  // Create TaskData
  std::shared_ptr<ppc::core::TaskData> taskDataPar = std::make_shared<ppc::core::TaskData>();

  if (world.rank() == 0) {
    const int count_size_vector = 100000;
    global_vec = beskhmelnova_k_most_different_neighbor_elements_mpi::getRandomVector<double>(count_size_vector);
    taskDataPar->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataPar->inputs_count.emplace_back(global_vec.size());
    taskDataPar->outputs.emplace_back(reinterpret_cast<uint8_t*>(global_out.data()));
    taskDataPar->outputs_count.emplace_back(global_out.size());
  }

  // Create Task
  beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskParallel<double> testMpiTaskParallel(taskDataPar);
  ASSERT_EQ(testMpiTaskParallel.validation(), true);
  testMpiTaskParallel.pre_processing();
  testMpiTaskParallel.run();
  testMpiTaskParallel.post_processing();

  if (world.rank() == 0) {
    // Create data
    std::vector<double> reference_out(2);

    // Create TaskData
    std::shared_ptr<ppc::core::TaskData> taskDataSeq = std::make_shared<ppc::core::TaskData>();
    taskDataSeq->inputs.emplace_back(reinterpret_cast<uint8_t*>(global_vec.data()));
    taskDataSeq->inputs_count.emplace_back(global_vec.size());
    taskDataSeq->outputs.emplace_back(reinterpret_cast<uint8_t*>(reference_out.data()));
    taskDataSeq->outputs_count.emplace_back(reference_out.size());

    // Create Task
    beskhmelnova_k_most_different_neighbor_elements_mpi::TestMPITaskSequential<double> testMpiTaskSequential(
        taskDataSeq);
    ASSERT_EQ(testMpiTaskSequential.validation(), true);
    testMpiTaskSequential.pre_processing();
    testMpiTaskSequential.run();
    testMpiTaskSequential.post_processing();

    ASSERT_NEAR(reference_out[0], global_out[0], 1e-10);
    ASSERT_NEAR(reference_out[1], global_out[1], 1e-10);
  }
>>>>>>> upstream/master
}
